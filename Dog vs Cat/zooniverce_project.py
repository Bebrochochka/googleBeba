# -*- coding: utf-8 -*-
"""Zooniverce_project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dCua0mf0PqanA-1aqaKXWvoUmxwu3597
"""

from tensorflow.keras.models import load_model
import librosa
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt

max_len = 88200

model = load_model("cnn-zooniverce.h5")

def prepare_data(smaple):
  sound, sr = librosa.load(smaple)

  if len(sound) > max_len:
        sound = sound[:max_len]
  else:
      sound = np.pad(sound, (0, max_len - len(sound)))

  sound = librosa.stft(sound)
  S = librosa.amplitude_to_db(np.abs(sound))
  return S, sr

st.title("Dog vs Cat Audio Classifier 🐶🐱")
file = st.file_uploader("Upload an audio of DOG or CAT", type=["mp3", "wav", "acc"])

if file:
    spectrogram, sr = prepare_data(file)

    # Визуализация спектрограммы
    fig, ax = plt.subplots()
    img = librosa.display.specshow(spectrogram, sr=22050)
    plt.colorbar(img, ax=ax, format="%+2.f dB")
    st.pyplot(fig)

    X = np.array(spectrogram, np.float32)
    X = X.reshape(1, 1025, 173, 1)
    prediction = model.predict(X)
    real_pred = ["Dog" if pred >= 0.5 else "Cat" for pred in prediction]
    st.write("Predicted class:",(real_pred))